#!/usr/bin/env python
#-*- coding: utf-8 -*-
#http://pastebin.com/V0fgzwTj
#Checkpoint 3
import sys
import socket
from urlparse import urlparse
import os
import time
from sys import stdout
import asyncore, socket
import logging 
from cStringIO import StringIO

#StringIO

#if you want GET, make header_getter true else make it false.
#first send header, get the contentlenght in the downloadbuffer then send getter
#and recieve the file.
#def downloaddata(filename, website, header_getter): if there is HEADER and GETTER
NL = '\r\n'
def downloaddata(filename, website):
	#get elements from parsing
	parsed = parsing(website)
	mypath, port, host, scheme = parsed[0], parsed[1], parsed[2], parsed[3]

	if scheme == "https":
		sys.exit("HTTPS is not supported.")

	#if you want GET, make header_getter true else make it false.

	# if header_getter:
	# 	variab = "GET "
	# else:
	# 	variab = "HEAD "

	http_request = "GET " + mypath + " HTTP/1.1" + NL + "Host: " + host + NL + NL
	#open socket
	#location = '/Users/Rin/Downloads/'
	dwnld_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
	dwnld_socket.connect((host,port))
	dwnld_socket.send(http_request)

	#start the download process
	downloadbuffer = ""
	while True:
		data = dwnld_socket.recv(32768)
		if len(data) == 0:
			break
		downloadbuffer = downloadbuffer + data
	dwnld_socket.close()

	header = downloadbuffer.split(NL)
	httpheader = header[0].split(" ")

	#REDICECT!!
	if httpheader == '301' or '302':
		data = downloadbuffer.split(NL)
		urldata = parsing(data[3])
		newhost, newport, newpath, newscheme = urldata[0], urldata[1], urldata[2], urldata[3]
		newhost = newhost.strip(" ")
		usethishost = urlparse(newhost)
		if newpath == None:
			newpath = "/"

		newhttp = "GET " + newpath + " HTTP/1.1" + NL + "Host: " + usethishost.hostname + NL + NL

		#open new socket
		new_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
		new_socket.connect((usethishost.hostname,newport))
		new_socket.send(newhttp)

		newdownloadbuffer = ""
		while True:
			newdata = new_socket.recv(32768)
			if len(newdata) == 0:
				break
			newdownloadbuffer = newdownloadbuffer + newdata

		return newdownloadbuffer

	else:
		return downloadbuffer

def findcontentandlastmod(filename, website):
	content_len = 0
	lastmod = ""

	b = []
	b = downloaddata(filename,website).split(NL+NL)
	for i in b:
		spl = i.split(" ")
		if spl[0] == "Content-Length:":
			content_len = spl[1]
		if spl[0] == "Last-Modified:":
			lastmod = spl[1]
	
	return content_len, lastmod

def writetofile(filename, data):
	b = []
	b = data.split(NL+NL)
	#write to a location in memory
	with open(filename,'wb') as myfile:
		myfile.write(b[1])

def parsing(website):
	url = urlparse(website)
	#find path
	if url.path == "":
		mypath = "/"
	else:
		mypath = url.path
		
	#find port
	if url.port == None:
		port = 80
	else:
		port = url.port
	host = url.hostname
	scheme = url.scheme
	return mypath, port, host, scheme

def writetempfile(filename, data, bytesrec):
	#write to a location in memory
	with open(filename + ".cr" + ".txt",'wb') as tempfile:
		b = []
		b = data.split(NL + NL)
		head = b[0].split(NL)[1:]
		for dat in head:
			newdat = dat.split(":")
			if newdat[0] == "Content-Length" or newdat[0] == "ETag" or newdat[0] == "Last-Modified":
				tempfile.write(dat+ NL)
		tempfile.write("Bytes-Received: " + str(len(bytesrec)))
	sys.exit("File has been downloaded.")

def getrange(path, host, bytes):
	#bytes = bytes recieved from original file (len)
	return ("GET {a} HTTP/1.1" + NL + "Host: {b}" + NL + "Connection: close" + NL + "Range: bytes={c}-" + NL + NL).format(a=path, b=host, c=bytes)

def resume(filename, website):
	content_len = ""
	etag = ""
	lastmodif = ""
	#Check if file exists, if exist then terminate program
	if os.path.exists(filename):
		#see if file size is the same as the content length
		fileinfo = os.stat(filename)
		#info about the headers kept in here
		contentetag = []		
		tempfilename = filename+".cr"+".txt"
		with open(tempfilename,'r') as tempfile:
			for line in tempfile:
				contentetag.append(line)
		res_file = open(filename, 'wb')
		#put content len, etag and last modi in variables
		for ele in contentetag:
			splele = ele.split(":")
			if splele[0] == "Content-Length":
				content_len = splele[1]
			if splele[0] == "ETag":
				etag = splele[1]
			if splele[0] == "Last-Modified":
				lastmodif += splele[1]


		a = parsing(website)
		path = a[0]
		port = a[1]
		host = a[2]

		#mamke new connection		
		dwnld_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
		dwnld_socket.connect((host,port))
		newhttp_request = getrange(path, host, fileinfo)
		dwnld_socket.send(newhttp_request)

		#start the download process
		new_head = ""
		downloadbuffer = ""
		while NL+NL not in new_head:
			data = dwnld_socket.recv(1)
			new_head = new_head + data
		while True:
			data = dwnld_socket.recv(32768)
			if len(data) == 0:
				break
			downloadbuffer = data
			res_file.write(downloadbuffer)
		dwnld_socket.close()
		res_file.close()

		writetempfile(filename, website, str(len(downloadbuffer)))
		#system will exit after this function is done because i put sys.exit in writetempfile

		#extract the content len and last mod
		extract = findcontentandlastmod(filename,website)
		content_len, lastmod = extract[0], extract[1]
		
	else:
		data = downloaddata(filename, website)
		writetofile(filename, data)
		#create a temp file for contentlen, bytes recieeved, last modified e-tag
		bytes_received = os.stat(filename)
		writetempfile(filename,data, bytes_received)

#--------------------------------------------------------------------------------------------------------------------------------------------------#

class HTTPClient(asyncore.dispatcher):
	## SIze of the buffer for each recv
	RECV_CHUNK_SIZE = 8192

	def __init__(self,url):
		asyncore.dispatcher.__init__(self)
		host, path, port = parse_url(url)

		#Create a logger
		self.logger = logging.getLogger(url)

		#Create a TCP socket to host at the right port
		self.create_socket(socket.AF_INET, socket.SOCK_STREAM)
		self.connect((host,port))

		self.host = host

		#Create recv buffer and send buffer
		(self.recvbuf, self.sendbuf) = (StringIO(), "")

		#Make initial request and deliver it.
		request = make_request('GET', path, {'Host': host})

		self.write(request)

	def write(self, data):
		"""Schedule to liver data over the socket"""
		self.sendbuf += data

	def handle_connect(self):
		self.logger.debug("Connected")

	#leave
	def handle_close(self):
		self.logger.debug("Disconnected")
		self.close()

	#leave
	def writeable(self):
		""" Check if there is anything to send"""
		return len(self.sendbuf) > 0

	#leave
	def handle_write(self):
		##If sendbuf is really really big, its not a good idea.
		bytes_sent = self.send(self.sendbuf)
		#Trimming
		self.sendbuf = self.sendbuf[bytes_sent:]

	#put old code in here
	def handle_read(self):
		recv_bytes = self.recv(HTTPClient.RECV_CHUNK_SIZE)
		self.logger.debug("recvd {} bytes".format(len(recv_bytes)))
		self.recvbuf.write(recv_bytes)

	#make download data function here

if __name__ == "__main__":
	# logging.basicConfig(level = logging.DEBUG, format = "%(asctime)-15s %(name)s: %(message)s")
	# clients = [HTTPClient("http://pantip.com/"), HTTPClient("http://www.muic.mahidol.ac.th/eng/"), HTTPClient("http://www.nytimes.com/"), HTTPClient("http://www.cnn.com/")]
	# asyncore.loop()
	if len(sys.argv) != 4:
		website = sys.argv[-1]
	 	connection_num = sys.argv[3]
	 	filename = sys.argv[2]
	 	#now ccall download with connection stuff
	else:
		website = sys.argv[-1]
		filename = sys.argv[2]
# 		filename = "abc.txt"
# 		website = "http://www.abc.com"
		resume(filename, website)
