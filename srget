#!/usr/bin/env python
#-*- coding: utf-8 -*-
#http://pastebin.com/V0fgzwTj
#Checkpoint 3
import sys
import socket as skt
from urlparse import urlparse
import os
import time
from sys import stdout
import asyncore, socket
import logging 
from cStringIO import StringIO

#StringIO

#if you want GET, make header_getter true else make it false.
#first send header, get the contentlenght in the downloadbuffer then send getter
#and recieve the file.
#def downloaddata(filename, website, header_getter): if there is HEADER and GETTER
NL = '\r\n'
def downloaddata(filename, website):

	#Open socket here (only one socket)
	#find contentLength of the file you want to download
	#splitDownloadRange(contentLength)
	#Create threadpool (number of threads depends on size.splitDownloadRange(contentLength)) here using 
	#	either asyncio or threading library (whichever is allowed)
	
	#For aThread in threadPool:
	#	threadedDownload(fromWheretoWhere,filename,website)
	#Note: fromWheretoWhere is drawn from the list given by splitDownloadRange(contentLength)
	#Note: filename should be a file already created beforehand
	#Everything in this function from here on should be moved to the threadedDownload function at the end of this file
	
	#get elements from parsing
	parsed = parsing(website)
	mypath, port, host, scheme = parsed[0], parsed[1], parsed[2], parsed[3]

	if scheme == "https":
		sys.exit("HTTPS is not supported.")

	#if you want GET, make header_getter true else make it false.

	# if header_getter:
	# 	variab = "GET "
	# else:
	# 	variab = "HEAD "

	#Change this request into something that allows you to download from a specific point
	http_request = "GET " + mypath + " HTTP/1.1" + NL + "Host: " + host + NL + NL
	#open socket
	#location = '/Users/Rin/Downloads/'
	print "httpreq", http_request
	dwnld_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
	dwnld_socket.settimeout(2)
	dwnld_socket.connect((host,port))
	dwnld_socket.send(http_request)

	print "done sockets"

	#start the download process
	downloadbuffer = ""
	while True:
		try:
			data = dwnld_socket.recv(32768)
		except skt.timeout:
			break
		downloadbuffer = downloadbuffer + data
	dwnld_socket.close()

	header = downloadbuffer.split(NL)
	httpheader = header[0].split(" ")

	print "before redirect"

	#REDICECT!!
	if 300<= int(httpheader[1])<=307:
		data = downloadbuffer.split(NL)
		urldata = parsing(data[3])
		newhost, newport, newpath, newscheme = urldata[0], urldata[1], urldata[2], urldata[3]
		newhost = newhost.strip(" ")
		usethishost = urlparse(newhost)
		if newpath == None:
			newpath = "/"

		newhttp = "GET " + newpath + " HTTP/1.1" + NL + "Host: " + usethishost.hostname + NL + NL

		#open new socket
		new_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
		new_socket.settimeout(2)
		new_socket.connect((usethishost.hostname,newport))
		new_socket.send(newhttp)

		newdownloadbuffer = ""
		while True:
			try:
				newdata = new_socket.recv(32768)
			except skt.timeout:
				break
			newdownloadbuffer = newdownloadbuffer + newdata

		return newdownloadbuffer

	elif 400<= int(httpheader[1]) <= 417:
		sys.exit("Client error")
	elif 500<= int(httpheader[1]) <= 505:
		sys.exit("Server error")
	else:
		return downloadbuffer

def findcontentandlastmod(filename, website):
	content_len = 0
	lastmod = ""

	header = downloaddata(filename,website).split(NL)
	for i in header:
		spl = i.split(" ")
		if spl[0] == "Content-Length:":
			content_len = spl[1:]
		if spl[0] == "Last-Modified:":
			lastmod = " ".join(spl[1:])
	
	return content_len, lastmod

def writetofile(filename, data):
	b = []
	b = data.split(NL+NL)
	#write to a location in memory
	with open(filename,'wb') as myfile:
		myfile.write(b[1])

def parsing(website):
	url = urlparse(website)
	#find path
	if url.path == "":
		mypath = "/"
	else:
		mypath = url.path
		
	#find port
	if url.port == None:
		port = 80
	else:
		port = url.port
	host = url.hostname
	scheme = url.scheme
	return mypath, port, host, scheme

def writetempfile(filename, data, bytesrec):
	#write to a location in memory
	with open(filename + ".cr" + ".txt",'wb') as tempfile:
		b = []
		b = data.split(NL + NL)
		head = b[0].split(NL)[1:]
		for dat in head:
			newdat = dat.split(":")
			if newdat[0] == "Content-Length" or newdat[0] == "ETag" or newdat[0] == "Last-Modified":
				tempfile.write(dat+ NL)
		tempfile.write("Bytes-Received: " + str(len(bytesrec)))
	sys.exit("File has been downloaded.")

def getrange(path, host, bytes):
	#bytes = bytes recieved from original file (len)
	return ("GET {a} HTTP/1.1" + NL + "Host: {b}" + NL + "Connection: close" + NL + "Range: bytes={c}-" + NL + NL).format(a=path, b=host, c=bytes)

def resume(filename, website):
	content_len = ""
	etag = ""
	lastmodif = ""
	#Check if file exists, if exist then terminate program
	if os.path.exists(filename):
		#see if file size is the same as the content length
		fileinfo = os.stat(filename)
		#info about the headers kept in here
		contentetag = []		
		tempfilename = filename+".cr"+".txt"
		with open(tempfilename,'r') as tempfile:
			for line in tempfile:
				contentetag.append(line)
		res_file = open(filename, 'wb')
		#put content len, etag and last modi in variables
		for ele in contentetag:
			splele = ele.split(":")
			if splele[0] == "Content-Length":
				content_len = splele[1]
			if splele[0] == "ETag":
				etag = splele[1]
			if splele[0] == "Last-Modified":
				lastmodif += splele[1]


		a = parsing(website)
		path = a[0]
		port = a[1]
		host = a[2]

		#mamke new connection		
		dwnld_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
		dwnld_socket.settimeout(2)
		dwnld_socket.connect((host,port))
		newhttp_request = getrange(path, host, fileinfo)
		dwnld_socket.send(newhttp_request)

		#start the download process
		new_head = ""
		downloadbuffer = ""
		while NL+NL not in new_head:
			data = dwnld_socket.recv(1)
			new_head = new_head + data
		while True:
			try:
				data = dwnld_socket.recv(32768)
			except skt.timeout:
				break
			downloadbuffer = data
			res_file.write(downloadbuffer)
		dwnld_socket.close()
		res_file.close()

		writetempfile(filename, website, str(len(downloadbuffer)))
		#system will exit after this function is done because i put sys.exit in writetempfile

		#extract the content len and last mod
		extract = findcontentandlastmod(filename,website)
		content_len, lastmod = extract[0], extract[1]
		
	else:
		data = downloaddata(filename, website)
		writetofile(filename, data)
		#create a temp file for contentlen, bytes recieeved, last modified e-tag
		bytes_received = os.stat(filename)
		writetempfile(filename,data, bytes_received)


#website = "http://www.muic.mahidol.ac.th/eng/wp-content/uploads/2016/10/TEA-banner-960x330-resized-1.jpg"
#website = "http://10.27.8.20:8080"
#website = "http://ipv4.download.thinkbroadband.com/100MB.zip"
#website = "http://www.abc.com"
#website = "http://10.27.8.20:8080/bigfile.xyz"
#website = "http://www.muic.mahidol.ac.th/eng/wp-content/uploads/2016/10/ShowCase_MUIC_en_033-resized.jpg"
#website = "http://www.muic.mahidol.ac.th/eng/wp-content/downloads/admission/example_of_mathematics.pdf"
#website = "http://pantip.com"
#website = "http://10.27.8.20:8080/primes1.txt"
#filename = "fmlhfhfy.txt"

filename = sys.argv[2]
website = sys.argv[-1]
resume(filename,website)


#close connection when you reach content length
#close connection even if you dont know the content length
